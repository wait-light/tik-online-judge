/*
Navicat MySQL Data Transfer

Source Server         : 127.0.0.1
Source Server Version : 50736
Source Host           : 127.0.0.1:3306
Source Database       : judge_cms

Target Server Type    : MYSQL
Target Server Version : 50736
File Encoding         : 65001

Date: 2022-01-17 14:17:22
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for cms_comment
-- ----------------------------
DROP TABLE IF EXISTS `cms_comment`;
CREATE TABLE `cms_comment` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `parent_id` bigint(20) unsigned DEFAULT NULL COMMENT '回复的id',
  `solution_id` bigint(11) unsigned DEFAULT NULL COMMENT '题解id',
  `uid` bigint(11) unsigned DEFAULT NULL COMMENT '评论人',
  `floor_id` bigint(20) unsigned DEFAULT NULL COMMENT '层id',
  `content` text COLLATE utf8mb4_unicode_ci COMMENT '评论内容',
  `create_time` datetime NOT NULL COMMENT '评论时间',
  `status` bit(1) DEFAULT b'1' COMMENT '状态(1启用/0禁用)',
  PRIMARY KEY (`id`,`create_time`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_comment
-- ----------------------------
INSERT INTO `cms_comment` VALUES ('1', null, '1', '1', null, 'tql', '2021-12-21 00:33:11', '');
INSERT INTO `cms_comment` VALUES ('3', null, '1', '1', null, '呵呵', '2021-12-21 00:42:18', '');
INSERT INTO `cms_comment` VALUES ('4', null, '1', '1', null, 'asdasd', '2021-12-21 00:43:16', '');
INSERT INTO `cms_comment` VALUES ('6', '2', '1', '1', '1', '英雄所见略同！！', '2021-12-21 00:59:22', '');
INSERT INTO `cms_comment` VALUES ('7', null, '2', '1', null, '呵呵', '2021-12-21 01:00:37', '');
INSERT INTO `cms_comment` VALUES ('8', null, '2', '1', null, '呵呵呵', '2021-12-21 01:00:43', '');
INSERT INTO `cms_comment` VALUES ('9', '7', '2', '1', '7', '你在呵呵什么', '2021-12-21 13:05:22', '');
INSERT INTO `cms_comment` VALUES ('10', '5', '1', '3', '4', '路过人间', '2021-12-21 13:34:18', '');
INSERT INTO `cms_comment` VALUES ('11', null, '3', '1', null, '留下评论', '2021-12-23 22:40:36', '');

-- ----------------------------
-- Table structure for cms_group
-- ----------------------------
DROP TABLE IF EXISTS `cms_group`;
CREATE TABLE `cms_group` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `name` varchar(64) COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT '群组名称',
  `create_time` datetime DEFAULT NULL COMMENT '创建时间',
  `create_user_id` bigint(20) unsigned DEFAULT NULL COMMENT '创建人id',
  `status` tinyint(3) unsigned DEFAULT '1' COMMENT '状态',
  `avatar` varchar(300) COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT '图片',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=16 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_group
-- ----------------------------
INSERT INTO `cms_group` VALUES ('15', '18计算机科学与技术一班', '2021-11-20 15:04:13', '1', '1', 'https://tik-online-judge.oss-cn-hangzhou.aliyuncs.com/2021-11-20/a5e2d90b-afa5-4bb8-af72-a1cb01aea491_marian-kroell-qElMHWePpok-unsplash.jpg');

-- ----------------------------
-- Table structure for cms_group_task
-- ----------------------------
DROP TABLE IF EXISTS `cms_group_task`;
CREATE TABLE `cms_group_task` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `group_id` bigint(20) unsigned DEFAULT NULL COMMENT '群组id',
  `task_id` bigint(20) unsigned DEFAULT NULL COMMENT '任务id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_group_task
-- ----------------------------
INSERT INTO `cms_group_task` VALUES ('4', '15', '4');

-- ----------------------------
-- Table structure for cms_group_user
-- ----------------------------
DROP TABLE IF EXISTS `cms_group_user`;
CREATE TABLE `cms_group_user` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `uid` bigint(20) unsigned DEFAULT NULL COMMENT '用户id',
  `group_id` bigint(20) unsigned DEFAULT NULL COMMENT '群组id',
  `user_type` tinyint(4) unsigned DEFAULT NULL COMMENT '群组用户类型',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_group_user
-- ----------------------------
INSERT INTO `cms_group_user` VALUES ('9', '1', '15', '1');
INSERT INTO `cms_group_user` VALUES ('14', '3', '15', '0');

-- ----------------------------
-- Table structure for cms_invite
-- ----------------------------
DROP TABLE IF EXISTS `cms_invite`;
CREATE TABLE `cms_invite` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `initiator` bigint(20) DEFAULT NULL COMMENT '邀请人',
  `invitees` bigint(20) DEFAULT NULL COMMENT '受邀人',
  `create_time` datetime DEFAULT NULL COMMENT '邀请时间',
  `status` int(11) DEFAULT '0' COMMENT '邀请状态',
  `group_id` bigint(20) DEFAULT NULL COMMENT '邀请到的群组',
  `update_time` datetime DEFAULT NULL COMMENT '处理时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci COMMENT='邀请信息表';

-- ----------------------------
-- Records of cms_invite
-- ----------------------------
INSERT INTO `cms_invite` VALUES ('1', '1', '3', '2021-11-20 21:06:31', '1', '15', '2021-11-20 21:07:01');
INSERT INTO `cms_invite` VALUES ('2', '1', '3', '2021-11-20 21:06:55', '1', '15', null);
INSERT INTO `cms_invite` VALUES ('3', '1', '3', '2021-11-20 22:47:20', '2', '15', '2021-11-20 22:47:43');
INSERT INTO `cms_invite` VALUES ('4', '1', '3', '2021-11-20 22:48:43', '1', '15', '2021-11-20 22:48:49');
INSERT INTO `cms_invite` VALUES ('5', '1', '3', '2021-11-20 22:48:57', '1', '15', '2021-11-20 22:49:02');
INSERT INTO `cms_invite` VALUES ('6', '1', '3', '2021-11-20 22:49:09', '2', '15', '2021-11-20 22:55:06');
INSERT INTO `cms_invite` VALUES ('7', '1', '3', '2021-11-20 22:55:32', '2', '15', '2021-11-20 22:55:36');
INSERT INTO `cms_invite` VALUES ('8', '3', '1', '2021-11-20 22:55:44', '1', '15', '2021-12-22 19:46:34');
INSERT INTO `cms_invite` VALUES ('9', '3', '1', '2021-12-22 19:47:08', '1', '15', null);

-- ----------------------------
-- Table structure for cms_solution
-- ----------------------------
DROP TABLE IF EXISTS `cms_solution`;
CREATE TABLE `cms_solution` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `uid` bigint(20) unsigned DEFAULT NULL COMMENT '题解用户id',
  `content` text COLLATE utf8mb4_unicode_ci COMMENT '题解内容',
  `create_time` datetime DEFAULT NULL COMMENT '创建时间',
  `update_time` datetime DEFAULT NULL COMMENT '修改时间',
  `status` bit(1) DEFAULT b'1' COMMENT '状态(1启用/0状态)',
  `problem_id` bigint(20) DEFAULT NULL COMMENT '问题id',
  `title` varchar(64) COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT '标题',
  `view` bigint(20) unsigned zerofill DEFAULT NULL COMMENT '浏览量',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_solution
-- ----------------------------
INSERT INTO `cms_solution` VALUES ('1', '1', '# 第一 绝对不意气用事\n![](https://tik-online-judge.oss-cn-hangzhou.aliyuncs.com/2021-12-24/b50ad148-8bdc-4223-bcc9-9946dc9a885e_image.png)\n# 第二 绝对不漏判任何一件坏事\n# 第三 绝对裁判得公正漂亮\n| 表头 | 表头 |\n| - | - |\n| 内容 | 内容 |\n\n`奥术大师多`', '2021-11-08 16:05:06', '2021-12-24 18:47:03', '', '1', '题解呵呵呵', '00000000000000000056');
INSERT INTO `cms_solution` VALUES ('2', '3', '# 安装\n\n1. 检查JAVA_HOME环境变量\n\n   ![image.png](https://i.loli.net/2021/10/08/x69jbLTE2d8ZtG5.jpg)\n\n2. 解压核心程序压缩包\n\n   放在一个非中文，无空格的文件夹中。\n\n3. 配置Maven环境变量\n\n   - MAVEN_HOM（M2_HOME）\n\n     地址为刚才解压出的文件的根目录。\n\n     ![image.png](https://i.loli.net/2021/10/08/Wq39JRDbjNUg1MP.jpg)\n\n   - 添加path\n\n     ![image.png](https://i.loli.net/2021/10/08/uHqeAPJWxlGIoD5.jpg)\n   \n4. 验证是否安装成功\n   在cmd中执行mvn -v，若是有相关版本输出，说明安装成功了。\n   ![image.png](https://i.loli.net/2021/10/08/fmhue5d9DLkT1rp.jpg)\n\n\n\n# Maven工程目录结构\n```\n		Hello\n		|---src\n		|---|---main\n		|---|---|---java\n		|---|---|---resources\n		|---|---test\n		|---|---|---java\n		|---|---|---resources\n		|---pom.xml\n```\n根目录：工程名\nsrc目录：源码\npom.xml：Maven的核心配置文件\nmain目录：存放主程序\ntest目录：存放测试程序\njava目录：存放Java源文件\nresources目录：存放框架或者其他工具的配置文件\n\n\n\n# Maven常用命令\n\n**执行与构建过程相关的Maven命令，必须进入pom.xml所在的目录。**\n\n**构建过程主要环节**\n\n①**清理**：删除以前的编译结果，为重新编译做好准备。\n②**编译**：将 Java 源程序编译为字节码文件。\n③**测试**：针对项目中的关键点进行测试，确保项目在迭代开发过程中关键点的正确性。\n④**报告**：在每一次测试后以标准的格式记录和展示测试结果。\n⑤**打包**：将一个包含诸多文件的工程封装为一个压缩文件用于安装或部署。Java 工程对应 jar 包，Web工程对应 war 包。\n⑥**安装**：在 Maven 环境下特指将打包的结果——jar 包或 war 包安装到本地仓库中。\n⑦**部署**：将打包的结果部署到远程仓库或将 war 包部署到服务器上运行\n\n## 命令\n\n- mvn clean 清理\n- mvn compile 编译主程序\n- mvn test-compile 编译测试程序\n- mvn test 执行测试\n- mvn package 打包\n- mvn install 安装当前Maven工程到仓库\n- mvn site 生成站点\n\n更多命令可以到本文**生命周期**中查看\n\n\n\n# Maven setting配置\n\n**maven默认配置setting.xml位置**：[用户家目录]\\\\.m2，即C:\\Users\\\\[用户名]\\\\.m2\n\n## 指定Maven工程JDK版本\n\n```xml\n<profile>\n    <id>jdk-1.8</id>\n    <activation>\n        <activeByDefault>true</activeByDefault>\n        <jdk>1.8</jdk>\n    </activation>\n    \n    <properties>\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n        <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>\n    </properties>\n</profile>\n```\n\n\n\n## 仓库\n\nMaven的核心程序中仅仅定义了抽象的生命周期，但是具体的工作必须由特定的插件来完成。而插件本身并不在Maven的核心程序中。当执行Maven命令需要用到某些插件时，Maven首先会到本地仓库中寻找，若是不存在则会到中央仓库下载，若是无法连接到中心仓库，或者插件不存在，则构建失败。\n\n**本地仓库默认位置**：[用户家目录]\\\\.m2\\\\repository ，即C:\\Users\\\\[用户名]\\\\.m2\\\\repository\n\n### 仓库保存的内容\n\n- Maven自身所需要的插件\n- 第三方框架或者工具的jar包\n- 自己开发的Maven工程\n\n### 修改仓库\n\n打开Maven根目录下的conf目录下的setting.xml\n\n#### 本地仓库\n\n修改\\<localRepository\\>\\</localRepository\\>\n\n```xml\n<!-- xxxx替换为指定的目录 -->\n<localRepository>xxxx</localRepository>\n```\n\n#### 远程仓库\n\n修改\\<mirrors\\>\\</mirrors\\>，添加mirror或者修改mirror。由于Maven中心仓库在中国下载速度慢，可以替换为国内仓库镜像。如下为阿里云仓库。\n\n```xml\n<mirror>\n    <id>alimaven</id>\n    <mirrorOf>central</mirrorOf>\n    <name>aliyun maven</name>\n    <url>http://maven.aliyun.com/nexus/content/repositories/central/</url>\n</mirror>\n```\n\n## 完整配置\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n\n  <localRepository>D:\\apache-maven-3.6.3\\maven-repository</localRepository>\n\n  <pluginGroups>\n  </pluginGroups>\n    \n  <proxies>\n  </proxies>\n\n  <servers>\n  </servers>\n    \n  <mirrors>\n    <mirror>\n      <id>alimaven</id>\n      <mirrorOf>central</mirrorOf>\n      <name>aliyun maven</name>\n      <url>http://maven.aliyun.com/nexus/content/repositories/central/</url>\n    </mirror>\n  </mirrors>\n\n  <profiles>\n    <profile>\n      <id>jdk-1.8</id>\n      <activation>\n        <activeByDefault>true</activeByDefault>\n        <jdk>1.8</jdk>\n      </activation>\n\n      <properties>\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n        <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>\n      </properties>\n    </profile>\n  </profiles>\n</settings>\n\n```\n\n\n\n# POM\n\n含义：Project Object Model（项目对象模型）\n\n## 坐标\n\n1. 使用下面三个向量唯一定位一个Maven工程\n\n- groupid：公司或组织域名倒序 + 项目名\n\n  ```xml\n  <groupid>com.atguigu.maven</groupid>\n  ```\n\n- artifactid：模块名\n\n  ```xml\n  <artifactid>Hello</artifactid>\n  ```\n\n- version：版本\n\n  ```xml\n  <version>1.0.0</version>\n  ```\n\n2. 仓库与坐标的对应关系\n\n   仓库中的文件路径与坐标一一对应。如上的坐标对应的仓库路径为：com/atguigu/maven/Hello/1.0.0\n\n## 依赖\n\n**样例**\n\n```xml\n<dependencies>\n    <!-- 单个依赖 -->\n    <!-- dependency必须在dependencies之中 -->\n    <dependency>\n        <!-- 公司或组织域名倒序 + 项目名 -->\n        <groupId>org.slf4j</groupId>\n        <!-- 模块名 -->\n        <artifactId>slf4j-log4j12</artifactId>\n        <!-- 版本 -->\n        <version>1.6.6</version>\n        <!-- 依赖范围 -->\n        <scope>compile</scope>\n    </dependency>\n</dependencies>\n```\n\n\n\n### 依赖范围\n\n**默认类型**：compile\n\n样例中的\\<scope\\>compile\\</scope\\>说明这个依赖是compile类型的。\n\n**类型**\n\n- compile\n- test\n\n![compile和test范围依赖](https://i.loli.net/2021/10/08/iqcR1t2DsSmlIJ5.jpg)\n\n- provided\n\n  *下图为Servlet-API参与的编译范围，其编译范围为provided*\n  \n  ![provided范围依赖](https://i.loli.net/2021/10/08/BPnEv5twx82RWQj.jpg)\n\n**三种类型对比**\n\n  ![image.png](http://ww1.sinaimg.cn/large/008c2CqBly1gmypklf74yj30uy054glw.jpg)\n\n解读：compile说明在编译主程序、测试程序、部署的时候都会参与进编译，而test只有在编译测试程序的时候会进行编译，provided不参与在部署的时候的编译。\n\n### 依赖的传递性\n\n**优点**：只需要在被需要的工程中添加依赖即可，无需在父工程中重复添加。有Maven统一管理。\n\n**注意**：只有依赖范围为compile的依赖才有传递性，其他类型不具有传递性。\n\n### 依赖的排除\n\n ```xml\n<exclusions>\n    <exclusion>\n        <groupId>avax.transaction</groupId>\n        <artifactId>javax.transaction-api</artifactId>\n    </exclusion>\n</exclusions>\n ```\n\n### 依赖原则\n\n- 就近原则\n\n  ![image.png](https://i.loli.net/2021/10/08/4PQvI6XUihzWLEw.jpg)\n\n- 先声明着优先（在dependencies的声明顺序）\n\n  ![image.png](https://i.loli.net/2021/10/08/gm6Hek9rslLBv8q.jpg)\n\n### 统一管理依赖版本号\n\n1. 设置properties\n ```xml\n<properties>\n    <!-- 自定义标签名 -->\n    <diy.version>5.0.2.RELEASE</diy.version>\n</properties>\n ```\n\n2. 使用 ${自定义的标签名} 统一管理\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jdbc</artifactId>\n    <!-- 填入统一管理的自定义标签 -->\n    <version>${diy.version}</version>\n</dependency>\n```\n\n### 依赖继承\n\n1. 建立Maven父工程\n\n   ```xml\n   <groupId>org.example</groupId>\n   <artifactId>father</artifactId>\n   <version>1.0-SNAPSHOT</version>\n   ```\n\n2. 子工程中声明父工程\n\n   ```xml\n   <parent>\n       <groupId>org.example</groupId>\n       <artifactId>father</artifactId>\n       <version>1.0-SNAPSHOT</version>\n       <!--以当前文件路径为基准的父工程的pom.xml路径-->\n       <relativePath>../father/pom.xml</relativePath>\n   </parent>\n   ```\n\n3. 子工程删除与父工程重复的内容(可以不删除)\n\n4. 在父工程中统一对依赖进行管理\n\n   ```xml\n   <dependencyManagement>\n       <dependencies>\n           <dependency>\n               <groupId>junit</groupId>\n               <artifactId>junit</artifactId>\n               <version>4.13.1</version>\n           </dependency>\n       </dependencies>\n   </dependencyManagement>\n   ```\n\n5. 删除子工程中父工程统一管理的依赖的版本信息\n\n   ~~\\<version\\>xxxx\\</version\\>~~\n\n**注意** : 配置继承后若是执行安装命令 , 则要先安装父工程\n\n### 聚合\n\n**作用**\n\n一键安装各个模块工程\n\n**配置**\n\n在聚合工程配置各个子工程的相对路径\n\n```xml\n<modules>\n    <!-- 子工程的相对路径 -->\n    <module>./child</module>\n</modules>\n```\n\n**使用**\n\n在聚合工作的pom.xml下执行mvn install\n\n### 构建\n\n**自动化构建**\n\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <artifactId>maven-invoker-plugin</artifactId>\n            <version>1.6</version>\n            <configuration>\n                <debug>true</debug>\n                <pomIncludes>\n                    <pomInclude>app-web-ui/pom.xml</pomInclude>\n                    <pomInclude>app-desktop-ui/pom.xml</pomInclude> \n                </pomIncludes>\n            </configuration>\n            <executions>\n                <execution>\n                    <id>build</id>\n                    <goals>\n                        <goal>run</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n<build>\n```\n\n[自动化构建 - 菜鸟教程](https://www.runoob.com/maven/maven-build-automation.html)\n\n#### 静态资源构建\n\n以下配置会使Maven构建时,将src/main/java下及其子目录下的所有properties和xml一起构建 , 即生成的target中会包含这些文件\n\n```xml\n<build>\n    <resources>\n        <resource>\n            <!-- 位置 -->\n            <directory>src/main/java</directory>\n            <!-- 包括哪些文件 -->\n            <includes>\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <!-- 关闭过滤，开启过滤的作用用指定的参数替换directory下的文件中的参数(eg. ${name}) -->\n            <filtering>false</filtering>\n        </resource>\n    </resources>\n</build>\n```\n\n### 查找依赖信息\n\n[mvnrepositor](https://mvnrepository.com)\n\n## 打包方式\n\n- war包\n\n  一个war包可以理解成一个web项目，里面是项目的所有东西\n\n- jar包\n\n  用于压缩和发布，打成包利于管理，主要存放项目需要的工具类\n\n- pom包\n\n  用在父级工程或聚合工程中，用来做jar包的版本控制\n\n```xml\n  <packaging>war</packaging>\n```\n\n## 完整配置\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <!-- 公司或组织域名倒序 + 项目名 -->\n    <groupId>org.example</groupId>\n    <!-- 模块名 -->\n    <artifactId>project_library</artifactId>\n    <!-- 版本 -->\n    <version>1.0-SNAPSHOT</version>\n\n    <!-- 打包方式 -->\n    <packaging>war</packaging>\n    <!-- 依赖 -->\n    <dependencies>\n        <dependency>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n            <version>1.6.6</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-jdbc</artifactId>\n            <version>${diy.version}</version>\n            <!-- 依赖排除 -->\n            <exclusions>\n                <exclusion>\n                    <groupId>avax.transaction</groupId>\n                    <artifactId>javax.transaction-api</artifactId>\n                </exclusion>\n            </exclusions>  \n        </dependency>\n    </dependencies>\n\n    <build>\n        <resources>\n            <resource>\n                <directory>src/main/java</directory>\n                <includes>\n                    <include>**/*.properties</include>\n                    <include>**/*.xml</include>\n                </includes>\n                <filtering>false</filtering>\n            </resource>\n            <resource>\n                <directory>src/main/resources</directory>\n                <includes>\n                    <include>**/*.properties</include>\n                    <include>**/*.xml</include>\n                </includes>\n                <filtering>false</filtering>\n            </resource>\n        </resources>\n    </build>\n</project>\n```\n\n\n\n# 生命周期\n\n## 标准生命周期\n\n- **clean**：项目清理的处理\n\n  - pre-clean：执行一些需要在clean之前完成的工作\n  - clean：移除所有上一次构建生成的文件\n  - post-clean：执行一些需要在clean之后立刻完成的工作\n\n- **default(或 build)**：项目部署的处理\n\n  一个典型的 Maven 构建（build）生命周期是由以下几个阶段的序列组成的：\n\n  ![img](https://i.loli.net/2021/10/08/WDCtwgk3VBEXazx.png)\n\n  | 生命周期阶段                                | 描述                                                         |\n  | :------------------------------------------ | :----------------------------------------------------------- |\n  | validate（校验）                            | 校验项目是否正确并且所有必要的信息可以完成项目的构建过程。   |\n  | initialize（初始化）                        | 初始化构建状态，比如设置属性值。                             |\n  | generate-sources（生成源代码）              | 生成包含在编译阶段中的任何源代码。                           |\n  | process-sources（处理源代码）               | 处理源代码，比如说，过滤任意值。                             |\n  | generate-resources（生成资源文件）          | 生成将会包含在项目包中的资源文件。                           |\n  | process-resources （处理资源文件）          | 复制和处理资源到目标目录，为打包阶段最好准备。               |\n  | compile（编译）                             | 编译项目的源代码。                                           |\n  | process-classes（处理类文件）               | 处理编译生成的文件，比如说对Java class文件做字节码改善优化。 |\n  | generate-test-sources（生成测试源代码）     | 生成包含在编译阶段中的任何测试源代码。                       |\n  | process-test-sources（处理测试源代码）      | 处理测试源代码，比如说，过滤任意值。                         |\n  | generate-test-resources（生成测试资源文件） | 为测试创建资源文件。                                         |\n  | process-test-resources（处理测试资源文件）  | 复制和处理测试资源到目标目录。                               |\n  | test-compile（编译测试源码）                | 编译测试源代码到测试目标目录.                                |\n  | process-test-classes（处理测试类文件）      | 处理测试源码编译生成的文件。                                 |\n  | test（测试）                                | 使用合适的单元测试框架运行测试（Juint是其中之一）。          |\n  | prepare-package（准备打包）                 | 在实际打包之前，执行任何的必要的操作为打包做准备。           |\n  | package（打包）                             | 将编译后的代码打包成可分发格式的文件，比如JAR、WAR或者EAR文件。 |\n  | pre-integration-test（集成测试前）          | 在执行集成测试前进行必要的动作。比如说，搭建需要的环境。     |\n  | integration-test（集成测试）                | 处理和部署项目到可以运行集成测试环境中。                     |\n  | post-integration-test（集成测试后）         | 在执行集成测试完成后进行必要的动作。比如说，清理集成测试环境。 |\n  | verify （验证）                             | 运行任意的检查来验证项目包有效且达到质量标准。               |\n  | install（安装）                             | 安装项目包到本地仓库，这样项目包可以用作其他本地项目的依赖。 |\n  | deploy（部署）                              | 将最终的项目包复制到远程仓库中与其他开发者和项目共享。       |\n\n- **site**：项目站点文档创建的处理\n\n  - pre-site：执行一些需要在生成站点文档之前完成的工作\n  - site：生成项目的站点文档\n  - post-site： 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备\n  - site-deploy：将生成的站点文档部署到特定的服务器上\n\n## 执行\n\nMaven核心程序为了更好的实现自动化构建，按照如下特点执行：不论要执行生命周期的哪一个阶段，都是从这个生命周期的最初的位置开始执行。\n\n例如：\n\n- 执行mvn clean，将运行以下两个生命周期阶段：pre-clean, clean\n- 执行mvn post-clean则运行以下三个生命周期阶段：pre-clean, clean, post-clean\n\n \n\n\n\n参考资料来源：[Maven构建生命周期-菜鸟教程](https://www.runoob.com/maven/maven-build-life-cycle.html)\n\n参考资料来源：[尚硅谷视频](http://www.atguigu.com)', '2021-11-20 21:17:50', '2021-11-20 21:41:01', '', '1', 'Maven记录', '00000000000000000003');
INSERT INTO `cms_solution` VALUES ('3', '1', '# 环境准备\n\n1. [Node Js](https://nodejs.org)\n\n2. [Git](https://git-scm.com/)\n\n3. [Visual Studio Code](https://code.visualstudio.com/Download)\n\n4. [Yeoman](https://yeoman.io)\n\n5. [VS Code Extension Generator](https://www.npmjs.com/package/generator-code)\n\n   ```sh\n   #通过npm安装Yeoman和VS Code Extension Generator.(安装Node Js后自带npm)\n   npm install -g yo generator-code\n   ```\n\n# Hello World\n\n构建一个简单的Hello World样例。\n\n1. 使用yo生成初始模板\n\n   ```sh\n   yo code\n   ```\n\n   交互式命令显示的内容大致如下\n\n   ```txt\n   # ? What type of extension do you want to create? New Extension (TypeScript)\n   #	你想创建什么类型的扩展插件？\n   \n   # ? What\'s the name of your extension? HelloWorld\n   # 你的插件的名字？\n   \n   # ? What\'s the identifier of your extension? helloworld\n   # 插件的唯一标识？\n   \n   # ? What\'s the description of your extension? LEAVE BLANK\n   # 插件的描述是什么？\n   \n   # ? Initialize a git repository? Yes\n   # 是否初始化 git 仓库？\n   \n   # ? Bundle the source code with webpack? No\n   # 是否使用 webpack 处理？\n   \n   # ? Which package manager to use? npm\n   # 使用什么包管理工具？\n   \n   # ? Do you want to open the new folder with Visual Studio Code? Open with `code`\n   # 是否用Visual Studio Code 打开新建的文件夹。\n   ```\n\n2. 运行Hello World插件\n\n   1. 使用 Vscode 打开刚才创建的文件夹。\n\n   2. 按 F5 键执行\n\n   3. 在新打开的窗口中按 Ctrl + Shift + P ，输入 Hello World\n\n      ![命令](https://s2.loli.net/2021/12/19/gUIPwuKAftplxHG.png)\n\n   4. 效果：显示消息Hello World\n\n      ![](https://s2.loli.net/2021/12/19/O3hZ9grJTHP2GYi.png)\n\n\n# 参考资料\n\n[visualstudio-extension官方文档](https://code.visualstudio.com/api)', '2021-01-26 20:39:57', '2021-12-21 20:39:57', '', null, 'Vscode Extension', '00000000000000000041');
INSERT INTO `cms_solution` VALUES ('4', '1', '# 问题\n直接使用数字或者字母代表一个状态验证时容易，但是在设置新的状态时容易与已有的状态表示混淆。\n\n# 二进制\n\n可以通过二进制表示的方式表示单一状态，二进制上的每一位表示一个状态。在验证时，同时满足所有的指定位置上有值时，则状态验证通过。\n* 状态表示\n\n	0b100 是否发布\n	0b010 是否启用\n	0b001 是否私人文章\n\n* 状态验证\n	\n	例如：\n\n	要验证一个文章是否为发布且启用且是私人文章的文章，则可以将其状态码通过位操作&(与)，将其和0b111相与，若相与的结果与0b111相同说明满足所需要的验证条件。\n\n	假设文章的状态码为0b101,与0b111相与后的结果为0b101,不满足条件。\n	即0b101 & 0b111 == 0b101 != 0b111\n\n# 状态改变\n\n改变指定位置。例如文章的状态码为0b101,要改变第二位的状态,操作如下：\n\n 0b101 ^ 0b010 \n\n使用异或将指定位置改变。其中背后一个数字为要改变的状态的状态码，在本文中的意思为：是否启用。\n\n# 最后\n二进制的具体操作可以查看参考资料的两篇文章，写的很详尽。\n\n**注意：**0b开头表示二进制\n\n**参考资料：**\n\n[IT_xiaozhang的博客](https://www.cnblogs.com/xiaoZhang521/p/11558011.html)\n[编程中位运算用法总结](https://blog.csdn.net/zhaozqcsdn/article/details/78470241?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~sobaiduend~default-1-78470241.nonecase&utm_term=位运算%20某一位置取反&spm=1000.2123.3001.4430)', '2021-12-21 21:34:25', '2021-12-21 21:34:25', '', null, '博客设计 - 文章状态设计', '00000000000000000017');
INSERT INTO `cms_solution` VALUES ('5', '1', '# @ConditionalOnProperty\n\n```java\n// 数组，获取对应property名称的值，与name不可同时使用\n	String[] value() default {};\n\n// 配置属性名称的前缀，比如spring.http.encoding\nString prefix() default \"\";\n\n// 数组，配置属性完整名称或部分名称\n// 可与prefix组合使用，组成完整的配置属性名称，与value不可同时使用\nString[] name() default {};\n\n// 可与name组合使用，比较获取到的属性值与havingValue给定的值是否相同，相同才加载配置\nString havingValue() default \"\";\n\n// 缺少该配置属性时是否可以加载。如果为true，没有该配置属性时也会正常加载；反之则不会生效\nboolean matchIfMissing() default false;\n```\n\n# @ConditionalOnClass\n\n当给定的类名在类路径上存在，则实例化当前Bean。\n\n# @ConditionalOnBean \n\n当给定的在bean存在时，则实例化当前Bean。\n\n# @ConditionalOnMissingBean\n\n当给定的在bean不存在时，则实例化当前Bean。\n\n# @ConditionalOnMissingClass\n\n当给定的类名在类路径上不存在，则实例化当前Bean。\n\n# @Import\n\n功能类似XML 里面的\\<import/\\> ,可以导入 @Configuration配置类，ImportSelector、ImportBeanDefinitionRegistrar 的实现，4.2 版本之后可以导入普通类。可以在类级别声明或作为元注释声明，会将配置类，实现的接口中的所有Bean全部加载，若是普通类也会将被导入，标记成Bean。\n\n# @Transactional\n\n用于开启某些类或者方法的事务，当放在方法上时，需要方法的访问级别为public。当把@Transactional 注解放在类级别时，表示所有该类的公共方法都配置相同的事务属性信息。\n\n**注意：**在spring mvc中，不要将此注解放在@Controller层，否则很容易导致一些其他问腿。\n\n| name             | 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 |\n| ---------------- | ------------------------------------------------------------ |\n| propagation      | 事务的传播行为，默认值为 REQUIRED。                          |\n| isolation        | 事务的隔离度，默认值采用 DEFAULT。                           |\n| timeout          | 事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 |\n| read-only        | 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 |\n| rollback-for     | 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 |\n| no-rollback- for | 抛出 no-rollback-for 指定的异常类型，不回滚事务。            |\n\n# @Scope\n\n@Scope注解是springIoc容器中的一个作用域，在 Spring IoC 容器中具有以下几种作用域：基本作用域singleton（单例）、prototype(多例)、Web 作用域（reqeust、session、globalsession）、自定义作用域。\n\n1. singleton单例模式 -- 全局有且仅有一个实例\n2. prototype原型模式 -- 每次获取Bean的时候会有一个新的实例\n3. request -- request表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效\n4. session -- session作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效\n5. globalsession -- global session作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义\n\nproxyMode属性。其值为ScopedProxyMode。ScopedProxyMode是一个枚举类，该类共定义了四个枚举值，分别为NO、DEFAULT、INTERFACE、TARGET_CLASS，其中DEFAULT和NO的作用是一样的。INTERFACES代表要使用JDK的动态代理来创建代理对象，TARGET_CLASS代表要使用CGLIB来创建代理对象。', '2021-12-21 21:41:51', '2021-12-21 21:41:51', '', null, 'spring注解', '00000000000000000003');
INSERT INTO `cms_solution` VALUES ('6', '1', '# CAP一致性(Consistency) 可用性(Availability) 分区容错性(Partition tolerance)\n\n## 核心\n\n一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。\n\n## CA\n\n单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。\n\n## CP \n\n满足一致性，分区容错性的系统，通常性能不是特别高。\n\n## AP \n\n满足可用性，分区容错性的系统，通常可能对一致性要求低一些。\n\n![image-20210124204110913](https://i.loli.net/2021/01/24/jrpcRLPInNQtqf3.png)\n\n# 分布式、集群简介\n\n**分布式**\n\n不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作。\n\n**集群**\n\n不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问。\n\n# 概述\n\n内存存储和持久化，redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务。\n\n# 数据类型\n\n## String\n\nstring是redis最基本的类型，可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象，一个redis中字符串value最多可以是512M。\n\n![image-20210124214533013](https://i.loli.net/2021/01/24/XOfSvpTD8Jr1KUg.png)\n\n![image-20210124214542875](https://i.loli.net/2021/01/24/3N5AWut7EVDFn6a.png)\n\n## Hash\n\nRedis hash 是一个键值对集合，是一个string类型的field和value的映射表，hash特别适合用于存储对象。类似Java里面的Map\\<String,Object\\>。\n\n![image-20210124214735716](https://i.loli.net/2021/01/24/gf59Vn3vOrsmGNb.png)\n\n## List\n\nRedis 列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。\n\n![image-20210124214608869](https://i.loli.net/2021/01/24/1rDKsVh5MaC4YXG.png)\n\n![image-20210124214656076](https://i.loli.net/2021/01/24/BDiRfWE6Tv4GUw8.png)\n\n## Set\n\nRedis的Set是string类型的无序集合。它是通过HashTable实现实现的。\n\n![](https://i.loli.net/2021/01/24/gf59Vn3vOrsmGNb.png)\n\n## zset (sorted set)\n\nRedis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的，但分数(score)却可以重复。\n\n![image-20210124214852876](https://i.loli.net/2021/01/24/mt4Qk1UhlaJI9Mo.png)\n\n![image-20210124214858389](https://i.loli.net/2021/01/24/OTSXlzhRM9t1Ipq.png)\n\n## 数据类型操作命令\n\n[文档](Http://redisdoc.com)\n\n# Redis键(key)\n\n## 常用键操作\n\n![image-20210124214324993](https://i.loli.net/2021/01/24/5qCUXRTS82pNkrL.png)\n\n# 配置文件\n\n## 常见配置\n\n1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程\n\n   daemonize no。\n\n2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定\n\n   pidfile /var/run/redis.pid\n\n3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字。\n\n   port 6379\n\n4. 绑定的主机地址\n\n   bind 127.0.0.1\n\n5. 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能\n\n​       timeout 300\n\n6. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose\n\n   loglevel verbose\n\n7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null\n\n   logfile stdout\n\n8. 设置数据库的数量，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id\n\n   databases 16\n\n9. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合\n\n10. save \\<seconds\\> \\<changes\\>\n       Redis默认配置文件中提供了三个条件：\n       save 900 1\n       save 300 10\n       save 60 10000\n       分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。\n\n11. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大\n\n    rdbcompression yes\n\n12. 指定本地数据库文件名，默认值为dump.rdb\n\n    dbfilename dump.rdb\n\n13. 指定本地数据库存放目录\n\n    dir ./\n\n14. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步\n\n    slaveof \\<masterip\\> \\<masterport\\>\n\n15. 当master服务设置了密码保护时，slav服务连接master的密码\n\n    masterauth \\<master-password\\>\n\n16. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH <password>命令提供密码，默认关\n\n    requirepass foobared\n\n17. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息\n\n    maxclients 128\n\n18. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区\n\n    maxmemory \\<bytes\\>\n\n19. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no\n\n    appendonly no\n\n20. 指定更新日志文件名，默认为appendonly.aof\n\n    appendfilename appendonly.aof\n\n21. 指定更新日志条件，共有3个可选值： \n\n    no：表示等操作系统进行数据缓存同步到磁盘（快） \n    always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） \n    everysec：表示每秒同步一次（折衷，默认值）\n    appendfsync everysec\n\n22. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中\n\n    vm-enabled no\n\n23. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享\n\n    vm-swap-file /tmp/redis.swap\n\n24. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0\n\n    vm-max-memory 0\n\n25. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值\n\n    vm-page-size 32\n\n26. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。\n\n    vm-pages 134217728\n\n27. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4\n\n    vm-max-threads 4\n\n28. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启\n\n    glueoutputbuf yes\n\n29. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法\n\n    hash-max-zipmap-entries 64\n\n    hash-max-zipmap-value 512\n\n30. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）\n\n    activerehashing yes\n\n31. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件\n\n    include /path/to/local.conf\n\n32. Log文件名字\n\n      logfile \"mylogfilexxx.log\"\n\n## Units 单位\n\n![image-20210124215116388](https://i.loli.net/2021/01/24/beq8A6yOpFZLVRf.png)\n\n- 配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit\n- 对大小写不敏感\n\n## INCLUDES 包含\n\n![image-20210124215249874](https://i.loli.net/2021/01/24/uv6SfZrjHOJK4Im.png)\n\n通过includes包含，redis.conf可以作为总闸，包含其他redis的配置文件。\n\n## SNAPSHOTTING 快照\n\n## save\n\n![image-20210124215452603](https://i.loli.net/2021/01/24/AX3H7aJp65WGvZm.png)\n\n```\n#以下配置意思为900秒钟若是有修改过1次及以上，则出发保存机制\nsave 900 1\n```\n\nRDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件。\n\n## Stop-writes-on-bgsave-error\n\n快照保存失败策略。\n\n![image-20210124215852524](https://i.loli.net/2021/01/24/97BMFNZVTQ2svzj.png)\n\nyes表示若是保存失败，则停止写入。\n\n## rdbcompression\n\n快照压缩策略\n\n![image-20210124220032732](https://i.loli.net/2021/01/24/Su9BtHipUg8wceQ.png)\n\n对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果不想消耗CPU来进行压缩的话，可以设置为关闭此功能。\n\n## rdbchecksum\n\n快照数据校验\n\n![image-20210124220112459](https://i.loli.net/2021/01/24/QNf5ld6MAaeCzEh.png)\n\n在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n\n## dbfilename\n\n快照文件名\n\n## dir\n\n快照位置\n\n## 安全配置\n\n### 命令\n\n```\n#将密码设置为xxxx\nconfig set requirepass \"xxxx\"\n#取消密码\nconfig set requirepass \"\"\n#认证,输入认证密码xxxx\nauth xxxx\n```\n\n## LIMITS\n\n限制\n\n### Maxclients\n\n最大客户端连接数量\n\n设置redis同时可以与多少个客户端进行连接。默认情况下为10000个客户端。当无法设置进程文件句柄限制时，redis会设置为当前的文件句柄限制值减去32，因为redis会为自身内部处理逻辑留一些句柄出来。如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。\n\n### Maxmemory\n\n最大内存\n\n设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。\n\n但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。\n\n### Maxmemory-policy\n\n最大内存策略\n\n（1）volatile-lru：使用LRU算法移除key，只对设置了过期时间的键\n（2）allkeys-lru：使用LRU算法移除key\n（3）volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键\n（4）allkeys-random：移除随机的key\n（5）volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key\n（6）noeviction：不进行移除。针对写操作，只是返回错误信息\n\n### Maxmemory-samples\n\n设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。\n\n\n\n\n\n# 持久化\n\n## RDB（Redis DataBase）\n\nRedis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。\n\n### Fork\n\nFork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。\n\n### dump.rdb\n\n持久化的文件名\n\n### 触发RDB快照\n\n- save命令\n  save时只管保存，其它不管，全部阻塞。\n\n- basave命令\n  Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastsave命令获取最后一次成功执行快照的时间。\n\n- flushall命令\n\n  执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义。\n\n### 恢复数据\n\n将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。CONFIG GET dir获取目录。\n\n### 优势\n\n- 适合大规模的数据恢复\n- 对数据完整性和一致性要求不高\n\n### 劣势\n\n- 在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改。\n\n- Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。\n\n### 停止\n\n```\nredis-cli config set save \"\"\n```\n\n\n\n## AOF（Append Only File）\n\n以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。\n\nAof保存的是appendonly.aof文件\n\n### 启动\n\n![image-20210124223239851](https://i.loli.net/2021/01/24/8baL3BFPSQoVOvM.png)\n\n### 数据恢复\n\n#### 正常恢复\n\n- 将有数据的aof文件复制一份保存到对应目录(config get dir)\n- 重启redis\n\n#### 异常恢复\n\n- Redis-check-aof --fix进行修复\n- 重启redis\n\n### Rewrite\n\nAOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof。\n\n#### 原理\n\nAOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中数据，每条记录有一条的Set语句。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。\n\n#### 触发机制\n\nRedis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。\n\n### 优势\n\n- appendfsync always\n\n  同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好。\n\n- appendfsync everysec\n\n  异步操作，每秒记录   如果一秒内宕机，有数据丢失。\n\n### 劣势\n\n- 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb\n- Aof运行效率要慢于rdb,每秒同步策略效率较好，不同步效率和rdb相同\n\n\n\n## 总结对比\n\nRDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储。AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。\n\n只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。\n\n同时开启两种持久化方式：\n\n        - 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。\n        - RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。\n\n**性能建议**\n\n\n因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。\n\n如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。\n\n如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构。\n\n\n\n# 事务\n\n一个队列中，一次性、顺序性、排他性的执行一系列命令。\n\n## 命令\n\n![image-20210124224709600](https://i.loli.net/2021/01/24/zeMtBylW9KbYJ15.png)\n\n## 全体连坐\n\n![image-20210124230653594](https://i.loli.net/2021/01/24/FYG7jwJvNcETeL9.png)\n\n## 冤头债主\n\n![image-20210124230727475](https://i.loli.net/2021/01/24/5MvUgKunoTeaHBR.png)\n\n## watch\n\n监控\n\n- 悲观锁\n\n  顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。\n\n- 乐观锁\n\n  顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。\n\n  - 乐观锁策略：提交版本必须大于记录当前版本才能执行更新\n\n- 乐观悲观对比\n\n  两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。\n\n  但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。本质上，数据库的乐观锁做法和悲观锁做法主要就是解决下面假设的场景，避免丢失更新问题：\n\nWatch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行。一旦执行了exec之前加的监控锁都会被取消掉了。\n\n![image-20210124232607963](https://i.loli.net/2021/01/24/3WiCPJByUvuSlhZ.png)\n\n\n\n## 阶段\n\n开启：以MULTI开始一个事务\n\n入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面\n\n执行：由EXEC命令触发事务\n\n## 特性\n\n- 单独的隔离操作\n\n  事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n- 没有隔离级别的概念\n\n  队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题。\n\n- 不保证原子性\n\n  redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。\n\n\n\n# 订阅\n\n进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。先订阅后发布后才能收到消息。\n\n![image-20210124232955825](https://i.loli.net/2021/01/24/XZTncILgm4FUKVM.png)\n\n## 命令\n\n![image-20210124233012860](https://i.loli.net/2021/01/24/SeXN9Ewvn3WLDfO.png)\n\n## 案例\n\n- 一次性订阅多个\n\n  SUBSCRIBE c1 c2 c3\n\n- 消息发布\n\n  PUBLISH c2 hello-redis\n\n- 订阅多个，通配符*\n  PSUBSCRIBE new*\n\n- 收取消息\n  PUBLISH new1 redis2015\n\n# 主从复制\n\n主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主。\n\n## 作用\n\n- 读写分离\n- 容灾恢复\n\n## 配置\n\n原则：配从(库)不配主(库) ，即在从库中进行配置。\n\n从库配置：slaveof 主库IP 主库端口\n\n```\nslaveof 192.168.1.15 6666\n```\n\n## 复制原理\n\n- Slave启动成功连接到master后会发送一个sync命令\n- Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，以完成一次完全同步。\n- - 增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步。\n  - 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。\n\n## 哨兵模式\n\n能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库\n\n### 配置\n\n1. 配置文件下新建sentinel.conf文件，名字绝不能错。\n\n2. 填写文件内容\n\n   ```\n    #最后一个数字1，表示主机挂掉后salve投票看让谁接替成为主机，得票数多少后成为主机\n    sentinel monitor [被监控数据库名字(自己起名字)] [ip] [端口] 1\n   ```\n\n3. 启动哨兵\n\n   ```\n   Redis-sentinel /myredis/sentinel.conf\n   ```\n\n## 复制的缺点\n\n由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。', '2021-12-21 23:01:08', '2021-12-21 23:01:08', '', null, 'redis笔记', '00000000000000000057');
INSERT INTO `cms_solution` VALUES ('7', '1', '## asd\n\naslkdfjlksjdflkjasdflkjlsadfjasdf\n\n```java\nasdasdasd\n```', '2021-12-22 00:16:34', '2021-12-23 21:23:31', '', null, 'asdasd', '00000000000000000003');
INSERT INTO `cms_solution` VALUES ('8', '1', '# 阿萨德\n![](https://tik-online-judge.oss-cn-hangzhou.aliyuncs.com/2021-12-23/bba31412-51a2-47bf-ae7a-4b74cd7b0d40_wolfgang-hasselmann-WrVvYxq11Yk-unsplash.jpg)\n\n## 奥术大师多\n## 到了\n# 奥术大师多\n## 奥术大师多', '2021-12-22 01:42:32', '2021-12-23 14:41:31', '', null, '导航栏测试', '00000000000000000005');

-- ----------------------------
-- Table structure for cms_task
-- ----------------------------
DROP TABLE IF EXISTS `cms_task`;
CREATE TABLE `cms_task` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `task_introduce` text COLLATE utf8mb4_unicode_ci COMMENT '任务介绍',
  `create_user_id` bigint(20) unsigned DEFAULT NULL COMMENT '任务发布人',
  `name` varchar(64) COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT '任务名称',
  `create_time` datetime DEFAULT NULL COMMENT '创建时间',
  `status` bit(1) DEFAULT b'1' COMMENT '状态',
  `begin_time` datetime DEFAULT NULL COMMENT '开始时间',
  `end_time` datetime DEFAULT NULL COMMENT '结束时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_task
-- ----------------------------
INSERT INTO `cms_task` VALUES ('4', null, '1', '全部完成测试', '2021-11-23 17:04:59', '', '2021-11-23 09:04:34', '2021-11-24 16:00:00');

-- ----------------------------
-- Table structure for cms_task_item
-- ----------------------------
DROP TABLE IF EXISTS `cms_task_item`;
CREATE TABLE `cms_task_item` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `task_id` bigint(20) unsigned DEFAULT NULL COMMENT '任务id',
  `problem_id` bigint(20) unsigned DEFAULT NULL COMMENT '问题id',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of cms_task_item
-- ----------------------------
INSERT INTO `cms_task_item` VALUES ('7', '4', '1');
